name: "default-qa-eval"
description: "Basic Q&A evaluation with L1 and L2 scorers"

data_source:
  source_type: jsonl
  path: "data/samples/golden_qa.jsonl"

scorers:
  - tier: L1
    scorer_name: keyword
    expected_keywords: []
    case_sensitive: false
    threshold: 0.5

  - tier: L1
    scorer_name: length
    min_length: 1
    max_length: 5000
    threshold: 1.0

  - tier: L2
    scorer_name: rouge
    rouge_types: ["rouge1", "rouge2", "rougeL"]
    threshold: 0.3

numerical_guard:
  enabled: false
